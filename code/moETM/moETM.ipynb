{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"code/moETM/moETM-main/\")\n",
    "outputs_dir = os.path.abspath(os.path.join(os.getcwd(), '../../../outputs'))\n",
    "save_dir = os.path.join(outputs_dir, \"different samples/CITE-SLN111-Gayoso-Mouse1toMouse2/moETM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongyj/.conda/envs/moetm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from moETM.train import Trainer_moETM_for_cross_prediction, Train_moETM_for_cross_prediction\n",
    "from moETM.build_model import build_moETM\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import anndata\n",
    "import torch\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 9264 × 13553\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'gene_ids', 'feature_types', 'highly_variable', 'highly_variable_mean_variance', 'encode', 'hvg_encode',\n",
       " AnnData object with n_obs × n_vars = 9264 × 110\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'protein_name',\n",
       " AnnData object with n_obs × n_vars = 7564 × 13553\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'gene_ids', 'feature_types', 'highly_variable', 'highly_variable_mean_variance', 'encode', 'hvg_encode',\n",
       " AnnData object with n_obs × n_vars = 7564 × 110\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'protein_name')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adata_mod1 = anndata.read(os.path.join(outputs_dir, \"different samples/CITE-SLN111-Gayoso-Mouse1toMouse2/moETM/train_gene_expression_data.h5ad\"))\n",
    "train_adata_mod2 = anndata.read(os.path.join(outputs_dir, \"different samples/CITE-SLN111-Gayoso-Mouse1toMouse2/moETM/train_protein_expression_data.h5ad\"))\n",
    "test_adata_mod1 = anndata.read(os.path.join(outputs_dir, \"different samples/CITE-SLN111-Gayoso-Mouse1toMouse2/moETM/test_gene_expression_data.h5ad\"))\n",
    "test_adata_mod2 = anndata.read(os.path.join(outputs_dir, \"different samples/CITE-SLN111-Gayoso-Mouse1toMouse2/moETM/test_protein_expression_data.h5ad\"))\n",
    "train_adata_mod1, train_adata_mod2, test_adata_mod1, test_adata_mod2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the batch information contained within the dataset stored in obs to the *batch_indices* column\n",
    "### The batch information needs to be encoded as integers. When the dataset does not contain batch information, the *batch_indices* column should be all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch_index = np.zeros(train_adata_mod1.shape[0])\n",
    "test_batch_index = np.zeros(test_adata_mod1.shape[0])\n",
    "train_adata_mod1.obs['batch_indices'] = train_batch_index\n",
    "test_adata_mod1.obs['batch_indices'] = test_batch_index\n",
    "train_adata_mod2.obs['batch_indices'] = train_batch_index\n",
    "test_adata_mod2.obs['batch_indices'] = test_batch_index\n",
    "\n",
    "train_batch_index, test_batch_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the gene expression data from the training and test sets and select highly variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(View of AnnData object with n_obs × n_vars = 9264 × 1633\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'gene_ids', 'feature_types', 'highly_variable', 'highly_variable_mean_variance', 'encode', 'hvg_encode',\n",
       " View of AnnData object with n_obs × n_vars = 7564 × 1633\n",
       "     obs: 'n_protein_counts', 'n_proteins', 'seurat_hash_id', 'batch_indices', 'hash_id', 'n_genes', 'percent_mito', 'leiden_subclusters', 'cell_types'\n",
       "     var: 'gene_ids', 'feature_types', 'highly_variable', 'highly_variable_mean_variance', 'encode', 'hvg_encode')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mod1 = train_adata_mod1.concatenate(test_adata_mod1, index_unique=None, join='outer')\n",
    "sc.pp.normalize_total(adata_mod1, target_sum=1e4)\n",
    "sc.pp.log1p(adata_mod1)\n",
    "sc.pp.highly_variable_genes(adata_mod1)\n",
    "index = adata_mod1.var['highly_variable'].values\n",
    "\n",
    "train_adata_mod1 = train_adata_mod1[:, index]\n",
    "test_adata_mod1 = test_adata_mod1[:, index]\n",
    "\n",
    "train_adata_mod1, test_adata_mod1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the gene expression and protein expression data of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.00530973,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.03293135, 0.00278293, 0.00278293, ..., 0.00185529, 0.00046382,\n",
       "         0.03107607],\n",
       "        [0.00400572, 0.00028612, 0.00057225, ..., 0.00057225, 0.00114449,\n",
       "         0.00572246],\n",
       "        [0.05660377, 0.00157233, 0.00471698, ..., 0.00078616, 0.00235849,\n",
       "         0.00471698],\n",
       "        ...,\n",
       "        [0.02497162, 0.00113507, 0.00605373, ..., 0.00075672, 0.00264851,\n",
       "         0.00870223],\n",
       "        [0.01254221, 0.00530632, 0.00192957, ..., 0.00048239, 0.00096479,\n",
       "         0.0067535 ],\n",
       "        [0.01175779, 0.00117578, 0.00058789, ..., 0.00058789, 0.00117578,\n",
       "         0.00646678]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mod1 = np.array(train_adata_mod1.X.todense())\n",
    "X_mod2 = np.array(train_adata_mod2.X.todense())\n",
    "batch_index = np.array(train_adata_mod1.obs['batch_indices'])\n",
    "\n",
    "X_mod1 = X_mod1 / X_mod1.sum(1)[:, np.newaxis]\n",
    "X_mod2 = X_mod2 / X_mod2.sum(1)[:, np.newaxis]\n",
    "\n",
    "X_mod1, X_mod2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0053, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0.0329, 0.0028, 0.0028,  ..., 0.0019, 0.0005, 0.0311],\n",
       "         [0.0040, 0.0003, 0.0006,  ..., 0.0006, 0.0011, 0.0057],\n",
       "         [0.0566, 0.0016, 0.0047,  ..., 0.0008, 0.0024, 0.0047],\n",
       "         ...,\n",
       "         [0.0250, 0.0011, 0.0061,  ..., 0.0008, 0.0026, 0.0087],\n",
       "         [0.0125, 0.0053, 0.0019,  ..., 0.0005, 0.0010, 0.0068],\n",
       "         [0.0118, 0.0012, 0.0006,  ..., 0.0006, 0.0012, 0.0065]],\n",
       "        device='cuda:0'),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mod1_train_T = torch.from_numpy(X_mod1).float().cuda()\n",
    "X_mod2_train_T = torch.from_numpy(X_mod2).float().cuda()\n",
    "batch_index_train_T = torch.from_numpy(batch_index).to(torch.int64).cuda()\n",
    "X_mod1_train_T, X_mod2_train_T, batch_index_train_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the gene expression and protein expression data of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.00645161, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.00212766]], dtype=float32),\n",
       " array([[0.02182673, 0.00167898, 0.00100739, ..., 0.00067159, 0.00100739,\n",
       "         0.01040967],\n",
       "        [0.03245887, 0.00177857, 0.00177857, ..., 0.00044464, 0.00177857,\n",
       "         0.0053357 ],\n",
       "        [0.01314252, 0.00175234, 0.00087617, ..., 0.00146028, 0.00087617,\n",
       "         0.01226636],\n",
       "        ...,\n",
       "        [0.06713589, 0.00108284, 0.00324851, ..., 0.00054142, 0.00162426,\n",
       "         0.00433135],\n",
       "        [0.01061947, 0.00318584, 0.00212389, ..., 0.00212389, 0.00141593,\n",
       "         0.00955752],\n",
       "        [0.0130427 , 0.00035733, 0.00089334, ..., 0.00017867, 0.00035733,\n",
       "         0.00696802]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mod1 = np.array(test_adata_mod1.X.todense())\n",
    "X_mod2 = np.array(test_adata_mod2.X.todense())\n",
    "batch_index = np.array(test_adata_mod1.obs['batch_indices'])\n",
    "\n",
    "sum1 = X_mod1.sum(1)\n",
    "sum2 = X_mod2.sum(1)\n",
    "\n",
    "X_mod1 = X_mod1 / X_mod1.sum(1)[:, np.newaxis]\n",
    "X_mod2 = X_mod2 / X_mod2.sum(1)[:, np.newaxis]\n",
    "\n",
    "X_mod1, X_mod2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0065, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0021]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0.0218, 0.0017, 0.0010,  ..., 0.0007, 0.0010, 0.0104],\n",
       "         [0.0325, 0.0018, 0.0018,  ..., 0.0004, 0.0018, 0.0053],\n",
       "         [0.0131, 0.0018, 0.0009,  ..., 0.0015, 0.0009, 0.0123],\n",
       "         ...,\n",
       "         [0.0671, 0.0011, 0.0032,  ..., 0.0005, 0.0016, 0.0043],\n",
       "         [0.0106, 0.0032, 0.0021,  ..., 0.0021, 0.0014, 0.0096],\n",
       "         [0.0130, 0.0004, 0.0009,  ..., 0.0002, 0.0004, 0.0070]],\n",
       "        device='cuda:0'),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mod1_test_T = torch.from_numpy(X_mod1).float().cuda()\n",
    "X_mod2_test_T = torch.from_numpy(X_mod2).float().cuda()\n",
    "batch_index_test_T = torch.from_numpy(batch_index).to(torch.int64).cuda()\n",
    "X_mod1_test_T, X_mod2_test_T, batch_index_test_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_mod1, X_mod2, batch_index\n",
    "test_mod1_sum, test_mod2_sum = sum1, sum2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(encoder(\n",
       "   (f1): Linear(in_features=1633, out_features=128, bias=True)\n",
       "   (act): ReLU()\n",
       "   (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (mu): Linear(in_features=128, out_features=200, bias=True)\n",
       "   (log_sigma): Linear(in_features=128, out_features=200, bias=True)\n",
       " ),\n",
       " encoder(\n",
       "   (f1): Linear(in_features=110, out_features=128, bias=True)\n",
       "   (act): ReLU()\n",
       "   (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (mu): Linear(in_features=128, out_features=200, bias=True)\n",
       "   (log_sigma): Linear(in_features=128, out_features=200, bias=True)\n",
       " ),\n",
       " decoder(),\n",
       " Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 1\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 2\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batch = len(batch_index_train_T.unique())\n",
    "input_dim_mod1 = X_mod1_train_T.shape[1]\n",
    "input_dim_mod2 = X_mod2_train_T.shape[1]\n",
    "train_num = X_mod1_train_T.shape[0]\n",
    "num_topic = 200\n",
    "emd_dim = 400\n",
    "encoder_mod1, encoder_mod2, decoder, optimizer = build_moETM(input_dim_mod1, input_dim_mod2, num_batch, num_topic=num_topic, emd_dim=emd_dim)\n",
    "encoder_mod1, encoder_mod2, decoder, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<moETM.train.Trainer_moETM_for_cross_prediction at 0x7fafbef7b2b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mod1, encoder_mod2, decoder = encoder_mod1.cuda(), encoder_mod2.cuda(), decoder.cuda()\n",
    "direction = 'rna_to_another'   # Or another_to_rna\n",
    "trainer = Trainer_moETM_for_cross_prediction(encoder_mod1, encoder_mod2, decoder, optimizer, direction)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "### Imputation results will be saved in *save_dir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 finished time 0.298075], Pearson_1=-0.0100, Spearmanr_1=-0.0191\n",
      "[epoch 10 finished time 0.037285], Pearson_1=0.3995, Spearmanr_1=0.3317\n",
      "[epoch 20 finished time 0.028025], Pearson_1=0.7309, Spearmanr_1=0.6190\n",
      "[epoch 30 finished time 0.053087], Pearson_1=0.8434, Spearmanr_1=0.7408\n",
      "[epoch 40 finished time 0.027536], Pearson_1=0.8633, Spearmanr_1=0.7693\n",
      "[epoch 50 finished time 0.041431], Pearson_1=0.8705, Spearmanr_1=0.7784\n",
      "[epoch 60 finished time 0.036843], Pearson_1=0.8709, Spearmanr_1=0.7775\n",
      "[epoch 70 finished time 0.046859], Pearson_1=0.8655, Spearmanr_1=0.7697\n",
      "[epoch 80 finished time 0.048313], Pearson_1=0.8621, Spearmanr_1=0.7639\n",
      "[epoch 90 finished time 0.056830], Pearson_1=0.8567, Spearmanr_1=0.7578\n",
      "[epoch 100 finished time 0.055963], Pearson_1=0.8570, Spearmanr_1=0.7592\n",
      "[epoch 110 finished time 0.058033], Pearson_1=0.8533, Spearmanr_1=0.7567\n",
      "[epoch 120 finished time 0.035613], Pearson_1=0.8357, Spearmanr_1=0.7369\n",
      "[epoch 130 finished time 0.062719], Pearson_1=0.8331, Spearmanr_1=0.7353\n",
      "[epoch 140 finished time 0.027656], Pearson_1=0.8291, Spearmanr_1=0.7340\n",
      "[epoch 150 finished time 0.034143], Pearson_1=0.8187, Spearmanr_1=0.7279\n",
      "[epoch 160 finished time 0.046937], Pearson_1=0.8420, Spearmanr_1=0.7420\n",
      "[epoch 170 finished time 0.023029], Pearson_1=0.8459, Spearmanr_1=0.7472\n",
      "[epoch 180 finished time 0.053493], Pearson_1=0.8651, Spearmanr_1=0.7679\n",
      "[epoch 190 finished time 0.042336], Pearson_1=0.8712, Spearmanr_1=0.7760\n",
      "[epoch 200 finished time 0.037683], Pearson_1=0.8649, Spearmanr_1=0.7675\n",
      "[epoch 210 finished time 0.043810], Pearson_1=0.8753, Spearmanr_1=0.7804\n",
      "[epoch 220 finished time 0.044077], Pearson_1=0.8757, Spearmanr_1=0.7792\n",
      "[epoch 230 finished time 0.040819], Pearson_1=0.8789, Spearmanr_1=0.7843\n",
      "[epoch 240 finished time 0.043388], Pearson_1=0.8745, Spearmanr_1=0.7807\n",
      "[epoch 250 finished time 0.039894], Pearson_1=0.8802, Spearmanr_1=0.7870\n",
      "[epoch 260 finished time 0.041710], Pearson_1=0.8777, Spearmanr_1=0.7839\n",
      "[epoch 270 finished time 0.040225], Pearson_1=0.8733, Spearmanr_1=0.7775\n",
      "[epoch 280 finished time 0.049246], Pearson_1=0.8771, Spearmanr_1=0.7839\n",
      "[epoch 290 finished time 0.042356], Pearson_1=0.8759, Spearmanr_1=0.7805\n",
      "[epoch 300 finished time 0.032907], Pearson_1=0.8774, Spearmanr_1=0.7840\n",
      "[epoch 310 finished time 0.049683], Pearson_1=0.8760, Spearmanr_1=0.7817\n",
      "[epoch 320 finished time 0.032907], Pearson_1=0.8753, Spearmanr_1=0.7798\n",
      "[epoch 330 finished time 0.035571], Pearson_1=0.8794, Spearmanr_1=0.7871\n",
      "[epoch 340 finished time 0.043086], Pearson_1=0.8770, Spearmanr_1=0.7842\n",
      "[epoch 350 finished time 0.042032], Pearson_1=0.8761, Spearmanr_1=0.7809\n",
      "[epoch 360 finished time 0.043053], Pearson_1=0.8779, Spearmanr_1=0.7866\n",
      "[epoch 370 finished time 0.043985], Pearson_1=0.8790, Spearmanr_1=0.7867\n",
      "[epoch 380 finished time 0.041426], Pearson_1=0.8768, Spearmanr_1=0.7850\n",
      "[epoch 390 finished time 0.047248], Pearson_1=0.8795, Spearmanr_1=0.7890\n",
      "[epoch 400 finished time 0.039988], Pearson_1=0.8785, Spearmanr_1=0.7867\n",
      "[epoch 410 finished time 0.044819], Pearson_1=0.8740, Spearmanr_1=0.7829\n",
      "[epoch 420 finished time 0.040611], Pearson_1=0.8787, Spearmanr_1=0.7888\n",
      "[epoch 430 finished time 0.040402], Pearson_1=0.8791, Spearmanr_1=0.7871\n",
      "[epoch 440 finished time 0.048609], Pearson_1=0.8768, Spearmanr_1=0.7876\n",
      "[epoch 450 finished time 0.040890], Pearson_1=0.8806, Spearmanr_1=0.7895\n",
      "[epoch 460 finished time 0.039712], Pearson_1=0.8787, Spearmanr_1=0.7890\n",
      "[epoch 470 finished time 0.040222], Pearson_1=0.8799, Spearmanr_1=0.7898\n",
      "[epoch 480 finished time 0.043137], Pearson_1=0.8794, Spearmanr_1=0.7880\n",
      "[epoch 490 finished time 0.037050], Pearson_1=0.8818, Spearmanr_1=0.7916\n",
      "[epoch 499 finished time 0.041986], Pearson_1=0.8784, Spearmanr_1=0.7903\n"
     ]
    }
   ],
   "source": [
    "Total_epoch = 500\n",
    "batch_size = 2000\n",
    "Train_set = [X_mod1_train_T, X_mod2_train_T, batch_index_train_T]\n",
    "Test_set = [X_mod1_test_T, X_mod2_test_T, batch_index_test_T, test_adata_mod1, test_mod1_sum, test_mod2_sum]\n",
    "Train_moETM_for_cross_prediction(trainer, Total_epoch, train_num, batch_size, Train_set, Test_set, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder_mod1, os.path.join(save_dir, \"encoder_mod1.pth\"))     \n",
    "torch.save(encoder_mod2, os.path.join(save_dir, \"encoder_mod2.pth\"))     \n",
    "torch.save(decoder, os.path.join(save_dir, \"decoder.pth\"))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moetm",
   "language": "python",
   "name": "moetm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
